{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting System\n",
    "\n",
    "The goal of this project is to create a voting system for bivariant sentiment analysis of any type of short reviews. To achieve this we are going to combine Naive Bayes algorithm from `nltk` and similar algorithms from `scikit-learn`. This combination should increase the accuracy and reliability of the confidence percentages. The training and testing will be done on the short reviews from https://pythonprogramming.net/.\n",
    "\n",
    "Note: We will also use `pickle` to save the trained classifiers and sets to reduce the running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def pickle_object(classifier, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        # Take contents of trained classifier and put it to the new file   \n",
    "        pickle.dump(classifier, f)\n",
    "\n",
    "def unpickle_object(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        return None\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Get trained classifier to work with it\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Load sets from serialised files\n",
    "training_sets = unpickle_object('training_sets.pickle')\n",
    "testing_sets = unpickle_object('testing_sets.pickle')\n",
    "\n",
    "# Load classifiers from serialised files\n",
    "naive_bayes_classifier = unpickle_object('naivebayes.pickle')\n",
    "MultinomialNB_classifier = unpickle_object('multinomialnb.pickle')\n",
    "BernoulliNB_classifier = unpickle_object('bernoullinb.pickle')\n",
    "LogisticRegression_classifier = unpickle_object('logistic_regression.pickle')\n",
    "SGDClassifier_classifier = unpickle_object('sgd_classifier.pickle')\n",
    "SVC_classifier = unpickle_object('svc_classifier.pickle')\n",
    "LinearSVC_classifier = unpickle_object('linear_svc_classifier.pickle')\n",
    "NuSVC_classifier = unpickle_object('nu_svc_classifier.pickle')\n",
    "\n",
    "\n",
    "# Upload and prepare training and testing sets if not done yet\n",
    "if training_sets is None or testing_sets is None:\n",
    "    short_pos = open('positive.txt', 'r').read()\n",
    "    short_neg = open('negative.txt', 'r').read()\n",
    "\n",
    "\n",
    "    # List speach parts that will be analysed by classifiers\n",
    "    allowed_word_types = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']\n",
    "    \n",
    "    # Create list of reviews with labels\n",
    "    documents = []\n",
    "\n",
    "    # Add each positive review on a separate line in documents\n",
    "    for review in short_pos.split('\\n'):\n",
    "        documents.append((review, 'pos'))\n",
    "\n",
    "   # Same for negative reviews\n",
    "    for review in short_neg.split('\\n'):\n",
    "        documents.append((review, 'neg'))\n",
    "\n",
    "   # Randomise reviews order to mix positives and negatives \n",
    "    random.shuffle(documents)\n",
    "\n",
    "\n",
    "    # Create list of most common words of allowed speach parts\n",
    "    all_words = []\n",
    "    # Tokenise each word in positive reviews\n",
    "    words = word_tokenize(short_pos)\n",
    "    # Add parts of speach tags to each tokenised word\n",
    "    pos = nltk.pos_tag(words)\n",
    "\n",
    "    # Collect to new list only those tagged words from positive reviews that are in allowed list\n",
    "    for w in pos:\n",
    "        if w[1] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    # Tokenise each word in negative reviews\n",
    "    words = word_tokenize(short_neg)\n",
    "    # Add parts of speach tags to each tokenised word\n",
    "    neg = nltk.pos_tag(words)\n",
    "    \n",
    "    # Collect to list with positives only those tagged words from negative reviews that are in allowed list\n",
    "    for w in pos:\n",
    "        if w[1] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    # Count number of occurances for each word and sort in desc. order\n",
    "    all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "    # Take 3000 most common from all available words\n",
    "    most_common = list(all_words.keys())[:3000]\n",
    "\n",
    "\n",
    "\n",
    "    def find_features(document):\n",
    "        words = word_tokenize(document)\n",
    "        features = {}\n",
    "        for word in most_common:\n",
    "            features[word] = word in words\n",
    "        return features\n",
    "\n",
    "    # Create a classification list in which each word marked to tell whether or not it is also in the list of most common words\n",
    "    feature_sets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "    # Create training set from the list of marked words\n",
    "    training_sets = feature_sets[:10500]\n",
    "    # Create testing set from the list of marked words that are not in training set\n",
    "    testing_sets = feature_sets[10500:]\n",
    "\n",
    "    # Serialise shuffled training set if not done\n",
    "    pickle_object(training_sets, 'training_sets.pickle')\n",
    "    # Serialise shuffled testing set if not done\n",
    "    pickle_object(testing_sets, 'testing_sets.pickle')\n",
    "\n",
    "\n",
    "# Train and serialise all classifiers if not done\n",
    "if naive_bayes_classifier is None:\n",
    "    # Train classifier on training sets\n",
    "    naive_bayes_classifier = nltk.NaiveBayesClassifier.train(training_sets)\n",
    "    # Serialise classifier\n",
    "    pickle_object(naive_bayes_classifier, 'naivebayes.pickle')\n",
    "\n",
    "if MultinomialNB_classifier is None:\n",
    "    MultinomialNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "    MultinomialNB_classifier.train(training_sets)\n",
    "    pickle_object(MultinomialNB_classifier, 'multinomialnb.pickle')\n",
    "\n",
    "if BernoulliNB_classifier is None:\n",
    "    BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "    BernoulliNB_classifier.train(training_sets)\n",
    "    pickle_object(BernoulliNB_classifier, 'bernoullinb.pickle')\n",
    "\n",
    "if LogisticRegression_classifier is None:\n",
    "    LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "    LogisticRegression_classifier.train(training_sets)\n",
    "    pickle_object(LogisticRegression_classifier, 'logistic_regression.pickle')\n",
    "\n",
    "if SGDClassifier_classifier is None:\n",
    "    SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "    SGDClassifier_classifier.train(training_sets)\n",
    "    pickle_object(SGDClassifier_classifier, 'sgd_classifier.pickle')\n",
    "\n",
    "if SVC_classifier is None:\n",
    "    SVC_classifier = SklearnClassifier(SVC())\n",
    "    SVC_classifier.train(training_sets)\n",
    "    pickle_object(SVC_classifier, 'svc_classifier.pickle')\n",
    "\n",
    "if LinearSVC_classifier is None:\n",
    "    LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "    LinearSVC_classifier.train(training_sets)\n",
    "    pickle_object(LinearSVC_classifier, 'linear_svc_classifier.pickle')\n",
    "\n",
    "if NuSVC_classifier is None:\n",
    "    NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "    NuSVC_classifier.train(training_sets)\n",
    "    pickle_object(NuSVC_classifier, 'nu_svc_classifier.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've uploaded processed and serialised training and testing datasets, as well as trained and serialised classifiers. Let's check their accuracy percentages at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.34146341463415"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Naive Bayes classifier from nltk accuracy on testing sets\n",
    "nltk.classify.accuracy(naive_bayes_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.95121951219512"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get accuracy on testing sets of MultinomialNB_classifier from sklearn \n",
    "nltk.classify.accuracy(MultinomialNB_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.95121951219512"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(BernoulliNB_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.34146341463415"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(LogisticRegression_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.78048780487805"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(SGDClassifier_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.1219512195122"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(SVC_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.90243902439023"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(LinearSVC_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.1219512195122"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(NuSVC_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a selected part of shuffled dataset all algorithms are doing fairly well. Now let's create a voting system for all classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    # Determine whether review is positive or negative\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "    # Give confidence percentages\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        chosen_votes = votes.count(mode(votes))\n",
    "        conf = chosen_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "    naive_bayes_classifier,\n",
    "    MultinomialNB_classifier,\n",
    "    BernoulliNB_classifier,\n",
    "    LogisticRegression_classifier, \n",
    "    SGDClassifier_classifier,\n",
    "    SVC_classifier,\n",
    "    LinearSVC_classifier,\n",
    "    NuSVC_classifier\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check accuracy of the voting system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.34146341463415"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(voted_classifier, testing_sets)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to run through our voting system several reviews to get their particular classification and confidence percentages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the review #20: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #21: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #22: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #23: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #24: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #25: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #26: neg\n",
      "Confidence in %: 50.0\n",
      "--------\n",
      "Classification of the review #27: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #28: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #29: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #30: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #31: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #32: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #33: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #34: neg\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #35: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n",
      "Classification of the review #36: pos\n",
      "Confidence in %: 75.0\n",
      "--------\n",
      "Classification of the review #37: neg\n",
      "Confidence in %: 87.5\n",
      "--------\n",
      "Classification of the review #38: neg\n",
      "Confidence in %: 62.5\n",
      "--------\n",
      "Classification of the review #39: pos\n",
      "Confidence in %: 100.0\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for x in range(20,40):\n",
    "    print(f'Classification of the review #{x}:', voted_classifier.classify(testing_sets[x][0]))\n",
    "    print('Confidence in %:', voted_classifier.confidence(testing_sets[x][0])*100)\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform sentiment analysis of any free text using our voting system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    features = find_features(text)\n",
    "    return voted_classifier.classify(features), voted_classifier.confidence(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 1.0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is awesome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 0.875)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is not so awesome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 0.75)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is not awesome!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 1.0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 0.875)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is not ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 1.0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('I think, my dress makes me look fat, but on the high heels I look better in it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg', 0.5)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('My dog has huge fangs, I think it has wolves in her close ancestors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "- We created a voting system based on many similar algorithms which gave us more reliable classification results. The final accuracy of the voting system is about `70%`. \n",
    "\n",
    "- We also compared confidence of the voting system on exclusively positive and negative reviews and found out that positive have significantly lower confidence percentages - only `69%`, while negative had `81%` of confidence.\n",
    " \n",
    "- On the level of individual reviews voting system gave us different results from `50%` of confidence to `100%`. Though, at first glance `50%` and lower seems to be not too comon of a result, for more information further research is required. \n",
    "\n",
    "- Sentiment analysis of free text gives more or less adequate results, though it has obvious flaws when sentences are more ambiguous in their belonging to a positive or negative connotation or contain adverb \"not\" in various positions. Nevetheless all these flaws are typical for bivariant classifiers, so to work successfully with such classifiers one should account for them."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a166e61b3f1e7b9ccc9f59f78d7cc3087a9ccbb0b1a7cff444b301613a633a54"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
