{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S.A. Presidential Vocabulary\n",
    "\n",
    "Whenever a United States of America president is elected or re-elected, an inauguration ceremony takes place to mark the beginning of the president’s term. During the ceremony, the president gives an inaugural address to the nation, dictating the tone and focus of the next four years of leadership.\n",
    "\n",
    "The goal of this project is to analyze the inaugural addresses of the presidents of the United States of America using word embeddings. By training sets of word embeddings on subsets of inaugural addresses, we can learn about the different ways in which the presidents use language to convey their agenda.\n",
    "\n",
    "\n",
    "## Data Loading\n",
    "\n",
    "The texts are are stored in separate files in the current directory. In order to create word embeddings on the corpus of all the presidents’ speeches, we need to read the text data from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-John-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-John-Q-Adam.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "\n",
    "# Find txt files in directory\n",
    "files = sorted([file for file in os.listdir() if file[-4:] == '.txt'])\n",
    "# Print first 10 presidents\n",
    "files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "  with open(file_name, 'r+', encoding='utf-8') as file:\n",
    "    file_text = file.read()\n",
    "  return file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fellow-Citizens of the Senate and of the House of Representatives:\\n\\nAmong the vicissitudes incident to life no event could have filled me with greater anxieties than that of which the notification was transmitted by your order, and received on the 14th day of the present month.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload files to speaches list\n",
    "speeches = [read_file(file) for file in files]\n",
    "# Print 1 sentence of the 1st speech\n",
    "speeches[0][0:278]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "Now we need to separate the files into sentences on a word by word basis and then merge all the sentences across the speeches into one big list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speeches(speeches):\n",
    "  word_tokenized_speeches = list()\n",
    "  for speech in speeches:\n",
    "    sentence_tokenizer = PunktSentenceTokenizer()\n",
    "    sentence_tokenized_speech = sentence_tokenizer.tokenize(speech)\n",
    "    word_tokenized_sentences = list()\n",
    "    for sentence in sentence_tokenized_speech:\n",
    "      word_tokenized_sentence = [word.lower().strip('.').strip('?').strip('!') for word in sentence.replace(\",\",\"\").replace(\"-\",\" \").replace(\":\",\"\").split()]\n",
    "      word_tokenized_sentences.append(word_tokenized_sentence)\n",
    "    word_tokenized_speeches.append(word_tokenized_sentences)\n",
    "  return word_tokenized_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fellow',\n",
       " 'citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'house',\n",
       " 'of',\n",
       " 'representatives',\n",
       " 'among',\n",
       " 'the',\n",
       " 'vicissitudes',\n",
       " 'incident',\n",
       " 'to',\n",
       " 'life',\n",
       " 'no',\n",
       " 'event',\n",
       " 'could',\n",
       " 'have',\n",
       " 'filled',\n",
       " 'me',\n",
       " 'with',\n",
       " 'greater',\n",
       " 'anxieties',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'which',\n",
       " 'the',\n",
       " 'notification',\n",
       " 'was',\n",
       " 'transmitted',\n",
       " 'by',\n",
       " 'your',\n",
       " 'order',\n",
       " 'and',\n",
       " 'received',\n",
       " 'on',\n",
       " 'the',\n",
       " '14th',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'present',\n",
       " 'month']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breakdown the speeches into words on a sentence by sentence basis\n",
    "processed_speeches = process_speeches(speeches)\n",
    "# Print 1 sentence of the 1st speech\n",
    "processed_speeches[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a custom set of word embeddings using `gensim`, we need to convert our data into a list of lists, where each inner list is a sentence and each item in the inner list is a word token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_speeches(speeches):\n",
    "  all_sentences = list()\n",
    "  for speech in speeches:\n",
    "    for sentence in speech:\n",
    "      all_sentences.append(sentence)\n",
    "  return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fellow',\n",
       " 'citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'house',\n",
       " 'of',\n",
       " 'representatives',\n",
       " 'among',\n",
       " 'the',\n",
       " 'vicissitudes',\n",
       " 'incident',\n",
       " 'to',\n",
       " 'life',\n",
       " 'no',\n",
       " 'event',\n",
       " 'could',\n",
       " 'have',\n",
       " 'filled',\n",
       " 'me',\n",
       " 'with',\n",
       " 'greater',\n",
       " 'anxieties',\n",
       " 'than',\n",
       " 'that',\n",
       " 'of',\n",
       " 'which',\n",
       " 'the',\n",
       " 'notification',\n",
       " 'was',\n",
       " 'transmitted',\n",
       " 'by',\n",
       " 'your',\n",
       " 'order',\n",
       " 'and',\n",
       " 'received',\n",
       " 'on',\n",
       " 'the',\n",
       " '14th',\n",
       " 'day',\n",
       " 'of',\n",
       " 'the',\n",
       " 'present',\n",
       " 'month']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of lists where each inner list is a sentence and each item in the inner list is a word token\n",
    "all_sentences = merge_speeches(processed_speeches)\n",
    "# Print 1 sentence of the 1st speech\n",
    "all_sentences[0][0:278]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we don't analyse common words let's remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove common english words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "all_sentences_filtered = [[word for word in sentence if not word in stop_words] for sentence in all_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigation of Most Common\n",
    "\n",
    "To get a better understanding of the data, let’s take a look at the most frequently used words across all the inaugural addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_words(list_of_sentences):\n",
    "  all_words = [word for sentence in list_of_sentences for word in sentence]\n",
    "  return Counter(all_words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('government', 575),\n",
       " ('people', 556),\n",
       " ('us', 469),\n",
       " ('upon', 365),\n",
       " ('must', 362),\n",
       " ('great', 336),\n",
       " ('may', 334),\n",
       " ('world', 310),\n",
       " ('states', 309),\n",
       " ('shall', 309),\n",
       " ('every', 299),\n",
       " ('country', 296),\n",
       " ('nation', 288),\n",
       " ('one', 254),\n",
       " ('new', 251),\n",
       " ('peace', 250),\n",
       " ('citizens', 241),\n",
       " ('power', 230),\n",
       " ('public', 221),\n",
       " ('time', 213),\n",
       " ('would', 209),\n",
       " ('constitution', 201),\n",
       " ('united', 198),\n",
       " ('nations', 187),\n",
       " ('america', 184),\n",
       " ('free', 183),\n",
       " ('freedom', 182),\n",
       " ('union', 171),\n",
       " ('war', 168),\n",
       " ('american', 159)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_words = most_frequent_words(all_sentences_filtered)\n",
    "most_freq_words[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Models\n",
    "\n",
    "New we are going to create our first word embedding model that contains word embeddings of all presidents, with `gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_presidents_embeddings = gensim.models.Word2Vec(all_sentences_filtered, window=5, min_count=1, workers=2, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our word embeddings, let’s have some fun exploring them. The concept of “freedom” is prevalent in the speeches made by the presidents. Let's find the top 20 words that are used in similar contexts to “freedom”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', 0.996030330657959),\n",
       " ('order', 0.995844841003418),\n",
       " ('love', 0.9955887794494629),\n",
       " ('history', 0.9955615401268005),\n",
       " ('mankind', 0.9955421686172485),\n",
       " ('happiness', 0.9955199360847473),\n",
       " ('prosperity', 0.9955078363418579),\n",
       " ('come', 0.9954904317855835),\n",
       " ('lasting', 0.9954744577407837),\n",
       " ('return', 0.995394229888916),\n",
       " ('result', 0.9953935146331787),\n",
       " ('greatest', 0.9953813552856445),\n",
       " ('greater', 0.9953355193138123),\n",
       " ('progress', 0.9952577948570251),\n",
       " ('promote', 0.9952285289764404),\n",
       " ('civilization', 0.9952123165130615),\n",
       " ('stability', 0.995141863822937),\n",
       " ('advancement', 0.9951395988464355),\n",
       " ('universal', 0.9951261281967163),\n",
       " ('courage', 0.9951251745223999)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words similar to \"freedom\"\n",
    "similar_to_freedom = all_presidents_embeddings.wv.most_similar(\"freedom\", topn=20)\n",
    "similar_to_freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about some controversial terms in human history: \"religion\" and \"God\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('real', 0.9990594983100891),\n",
       " ('offer', 0.9990562796592712),\n",
       " ('operation', 0.9990289211273193),\n",
       " ('tranquillity', 0.9989761710166931),\n",
       " ('devoted', 0.9989373087882996),\n",
       " ('show', 0.998914361000061),\n",
       " ('accomplish', 0.9989013075828552),\n",
       " ('favored', 0.9988955855369568),\n",
       " ('abuses', 0.9988954663276672),\n",
       " ('railroads', 0.9988946914672852),\n",
       " ('expression', 0.9988880753517151),\n",
       " ('held', 0.998881459236145),\n",
       " ('crisis', 0.9988803267478943),\n",
       " ('necessity', 0.9988754391670227),\n",
       " ('permit', 0.9988753795623779),\n",
       " ('enlightened', 0.9988750219345093),\n",
       " ('effected', 0.9988733530044556),\n",
       " ('purposes', 0.9988710880279541),\n",
       " ('renew', 0.9988645315170288),\n",
       " ('scarcely', 0.9988604187965393)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words similar to \"religion\"\n",
    "similar_to_religion = all_presidents_embeddings.wv.most_similar(\"religion\", topn=20)\n",
    "similar_to_religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solemn', 0.9954308271408081),\n",
       " ('bless', 0.9952143430709839),\n",
       " ('taken', 0.9945979714393616),\n",
       " ('take', 0.994469940662384),\n",
       " ('support', 0.9943830966949463),\n",
       " ('ask', 0.9943631291389465),\n",
       " ('suffrages', 0.9941916465759277),\n",
       " ('office', 0.9941672682762146),\n",
       " ('almighty', 0.9940996766090393),\n",
       " ('today', 0.994083821773529),\n",
       " ('confidence', 0.9940829873085022),\n",
       " ('trust', 0.9939519762992859),\n",
       " ('entitled', 0.9939282536506653),\n",
       " ('day', 0.9939256906509399),\n",
       " ('friends', 0.9938493371009827),\n",
       " ('called', 0.9938339591026306),\n",
       " ('high', 0.9937537312507629),\n",
       " ('portion', 0.9937481880187988),\n",
       " ('duty', 0.9937167167663574),\n",
       " ('distinguished', 0.9937167167663574)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words similar to \"God\"\n",
    "similar_to_god = all_presidents_embeddings.wv.most_similar(\"god\", topn=20)\n",
    "similar_to_god"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a revelation...\n",
    "\n",
    "\n",
    "## One President\n",
    "An interesting aspect of word embeddings is to see how different corpora result in different word embeddings, alluding to differences in how words are used between writers/authors/speakers.\n",
    "\n",
    "Let’s train a word embedding model on a single president and see how their word embeddings differ from the collection of all presidents. We are going to use President Franklin D. Roosevelt’s speeches as a example here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_president_sentences(president):\n",
    "  files = sorted([file for file in os.listdir() if president.lower() in file.lower()])\n",
    "  speeches = [read_file(file) for file in files]\n",
    "  processed_speeches = process_speeches(speeches)\n",
    "  all_sentences = merge_speeches(processed_speeches)\n",
    "  all_sentences_filtered = [[word for word in sentence if not word in stop_words] for sentence in all_sentences]\n",
    "  return all_sentences_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "roosevelt_sent = get_president_sentences('Franklin-D-Roosevelt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of President Franklin D Roosevelt’s speeches, let’s take a look at the most frequently used words across his inaugural addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nation', 26),\n",
       " ('people', 25),\n",
       " ('government', 23),\n",
       " ('us', 20),\n",
       " ('shall', 20),\n",
       " ('democracy', 20),\n",
       " ('men', 18),\n",
       " ('must', 17),\n",
       " ('know', 16),\n",
       " ('life', 15),\n",
       " ('spirit', 15),\n",
       " ('upon', 13),\n",
       " ('national', 12),\n",
       " ('years', 12),\n",
       " ('may', 12),\n",
       " ('new', 12),\n",
       " ('world', 12),\n",
       " ('every', 11),\n",
       " ('states', 11),\n",
       " ('way', 11),\n",
       " ('good', 11),\n",
       " ('today', 10),\n",
       " ('great', 10),\n",
       " ('power', 10),\n",
       " ('progress', 10),\n",
       " ('old', 10),\n",
       " ('united', 10),\n",
       " ('see', 10),\n",
       " ('time', 9),\n",
       " ('first', 9)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_words(roosevelt_sent)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with our previous word embedding model, let’s explore roosevelt_embeddings! We are going to find the top 20 words that are used in similar contexts to \"freedom\" and \"god\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "roosevelt_embeddings = gensim.models.Word2Vec(roosevelt_sent, window=5, min_count=1, workers=2, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ideals', 0.3555612564086914),\n",
       " ('challenge', 0.2985445261001587),\n",
       " ('engaging', 0.28151440620422363),\n",
       " ('alike', 0.2713252305984497),\n",
       " ('faithful', 0.27098703384399414),\n",
       " ('employment', 0.26910820603370667),\n",
       " ('secure', 0.25979623198509216),\n",
       " ('elementary', 0.2574740946292877),\n",
       " ('pall', 0.24631841480731964),\n",
       " ('fatalistic', 0.2450205534696579),\n",
       " ('proclaimed', 0.24280594289302826),\n",
       " ('irresistible', 0.2389444261789322),\n",
       " ('experiment', 0.23624424636363983),\n",
       " ('almighty', 0.23192434012889862),\n",
       " ('performance', 0.2289603352546692),\n",
       " ('emerson', 0.22857506573200226),\n",
       " ('remaining', 0.22777263820171356),\n",
       " ('creeds', 0.2275572270154953),\n",
       " ('ahead', 0.2275373935699463),\n",
       " ('recent', 0.2264631986618042)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roosevelt_similar_to_freedom = roosevelt_embeddings.wv.most_similar(\"freedom\", topn=20)\n",
    "roosevelt_similar_to_freedom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reason', 0.35487619042396545),\n",
       " ('patchwork', 0.3050941824913025),\n",
       " ('speaks', 0.29313454031944275),\n",
       " ('wage', 0.28905582427978516),\n",
       " ('require', 0.27758654952049255),\n",
       " ('lending', 0.26661258935928345),\n",
       " ('declaration', 0.2642853260040283),\n",
       " ('greatest', 0.25546571612358093),\n",
       " ('away', 0.2506450116634369),\n",
       " ('tried', 0.2505795359611511),\n",
       " ('productiveness', 0.24845187366008759),\n",
       " ('warm', 0.23641154170036316),\n",
       " ('changed', 0.23600950837135315),\n",
       " (\"country's\", 0.23365409672260284),\n",
       " ('kept', 0.22523440420627594),\n",
       " ('earth', 0.22172710299491882),\n",
       " ('host', 0.22088958323001862),\n",
       " ('translated', 0.2172420769929886),\n",
       " ('move', 0.2169693410396576),\n",
       " ('lines', 0.2168179303407669)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roosevelt_similar_to_god = roosevelt_embeddings.wv.most_similar(\"god\", topn=20)\n",
    "roosevelt_similar_to_god"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results we see from speeches of one president (even with 4 speeches to work with) compose not enough data to produce robust word embeddings. So in the next section, we will be looking at the speeches of multiple presidents to increase our corpus size and produce better word embeddings.\n",
    "\n",
    "## Selection of Presidents\n",
    "\n",
    "Let’s increase our corpus size and find more defined word embeddings by training a word embedding model on the inaugural addresses of a collection of four presidents featured on Mount Rushmore in Keystone: George Washington, Thomas Jefferson, Theodore Roosevelt, and Abraham Lincoln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_presidents_sentences(presidents):\n",
    "  all_sentences = list()\n",
    "  for president in presidents:\n",
    "    files = sorted([file for file in os.listdir() if president.lower() in file.lower()])\n",
    "    speeches = [read_file(file) for file in files]\n",
    "    processed_speeches = process_speeches(speeches)\n",
    "    all_prez_sentences = merge_speeches(processed_speeches)\n",
    "    all_sentences.extend(all_prez_sentences)\n",
    "    all_sentences_filtered = [[word for word in sentence if not word in stop_words] for sentence in all_sentences]\n",
    "  return all_sentences_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushmore_presidents_sent = get_presidents_sentences([\"washington\",\"jefferson\",\"lincoln\",\"theodore-roosevelt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of President Washington, Jefferson, Lincoln, and Theodore Roosevelt’s speeches, let’s take a look at the most frequently used words across their inaugural addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('government', 46),\n",
       " ('shall', 42),\n",
       " ('may', 41),\n",
       " ('constitution', 34),\n",
       " ('people', 33),\n",
       " ('us', 32),\n",
       " ('citizens', 30),\n",
       " ('union', 29),\n",
       " ('one', 28),\n",
       " ('public', 28),\n",
       " ('would', 25),\n",
       " ('must', 25),\n",
       " ('every', 24),\n",
       " ('states', 24),\n",
       " ('fellow', 23),\n",
       " ('right', 21),\n",
       " ('law', 20),\n",
       " ('upon', 19),\n",
       " ('state', 18),\n",
       " ('war', 18),\n",
       " ('among', 17),\n",
       " ('good', 17),\n",
       " ('country', 16),\n",
       " ('great', 16),\n",
       " ('power', 16),\n",
       " ('peace', 15),\n",
       " ('present', 14),\n",
       " ('nation', 13),\n",
       " ('let', 13),\n",
       " ('others', 13)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_words(rushmore_presidents_sent)[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the sentences from the presidents featured on Mount Rushmore, let's create another word embedding model with gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushmore_embeddings = gensim.models.Word2Vec(rushmore_presidents_sent, window=5, min_count=1, workers=2, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with our previous word embedding models, let’s explore rushmore_embeddings. We will find words that are used in similar contexts to \"freedom\" and \"god\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('given', 0.404973566532135),\n",
       " ('shall', 0.40488311648368835),\n",
       " ('union', 0.3774382472038269),\n",
       " ('first', 0.36965152621269226),\n",
       " ('made', 0.36015552282333374),\n",
       " ('power', 0.3592836856842041),\n",
       " ('war', 0.3586719036102295),\n",
       " ('foreign', 0.35098040103912354),\n",
       " ('happiness', 0.34960997104644775),\n",
       " ('treaties', 0.3417947292327881),\n",
       " ('duty', 0.3409098982810974),\n",
       " ('equal', 0.3394305408000946),\n",
       " ('therefore', 0.33861058950424194),\n",
       " ('demanded', 0.33720552921295166),\n",
       " ('every', 0.331023246049881),\n",
       " ('understand', 0.33005741238594055),\n",
       " ('authority', 0.32939761877059937),\n",
       " ('great', 0.32142385840415955),\n",
       " ('pretext', 0.32085418701171875),\n",
       " ('right', 0.3182717263698578)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rushmore_similar_to_freedom = rushmore_embeddings.wv.most_similar(\"freedom\", topn=20)\n",
    "rushmore_similar_to_freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('government', 0.5442899465560913),\n",
       " ('war', 0.5255405306816101),\n",
       " ('public', 0.5180131196975708),\n",
       " ('without', 0.5116174221038818),\n",
       " ('would', 0.49037110805511475),\n",
       " ('may', 0.47593018412590027),\n",
       " ('one', 0.4694865643978119),\n",
       " ('union', 0.4660675525665283),\n",
       " ('us', 0.4656261205673218),\n",
       " ('every', 0.4608868360519409),\n",
       " ('must', 0.4579213559627533),\n",
       " ('shall', 0.4526175856590271),\n",
       " ('constitution', 0.4501025378704071),\n",
       " ('citizens', 0.44717520475387573),\n",
       " ('best', 0.4436720609664917),\n",
       " ('duty', 0.43555450439453125),\n",
       " ('among', 0.4316003620624542),\n",
       " ('present', 0.43008318543434143),\n",
       " ('happiness', 0.4292805790901184),\n",
       " ('nation', 0.42901843786239624)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rushmore_similar_to_god = rushmore_embeddings.wv.most_similar(\"god\", topn=20)\n",
    "rushmore_similar_to_god"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('public', 0.737883448600769),\n",
       " ('union', 0.7208378911018372),\n",
       " ('law', 0.7080079317092896),\n",
       " ('shall', 0.6866411566734314),\n",
       " ('may', 0.6857576370239258),\n",
       " ('would', 0.6808280348777771),\n",
       " ('must', 0.6720712780952454),\n",
       " ('citizens', 0.669371485710144),\n",
       " ('nation', 0.669234037399292),\n",
       " ('national', 0.6657862067222595),\n",
       " ('us', 0.657419741153717),\n",
       " ('one', 0.6548988223075867),\n",
       " ('duty', 0.6467574834823608),\n",
       " ('war', 0.645211398601532),\n",
       " ('best', 0.6441528797149658),\n",
       " ('without', 0.6408768892288208),\n",
       " ('among', 0.6387364864349365),\n",
       " ('people', 0.6376473307609558),\n",
       " ('states', 0.6195920705795288),\n",
       " ('every', 0.6142016649246216)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rushmore_similar_to_government = rushmore_embeddings.wv.most_similar(\"government\", topn=20)\n",
    "rushmore_similar_to_government"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "\n",
    "We have trained sets of 'word embeddings' on the whole set and some subsets of inaugural addresses and revealed that presidents as a whole, a \"Rushmore group\" of presidents and even one particular president use different lexicon and emphasise different things in their speeches. Such common used words for American people as \"freedom\" and \"god\" are also used by different groups in different contexts. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a166e61b3f1e7b9ccc9f59f78d7cc3087a9ccbb0b1a7cff444b301613a633a54"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
